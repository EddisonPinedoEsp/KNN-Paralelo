# KNN Paralelo con MPI

Este proyecto implementa una versi√≥n **paralela** del algoritmo **K-Nearest Neighbors (KNN)** utilizando **MPI (Message Passing Interface)** con la biblioteca [`mpi4py`](https://mpi4py.readthedocs.io/en/stable/). El objetivo es **distribuir el c√°lculo de las distancias** y la predicci√≥n de clases entre m√∫ltiples procesos para mejorar el rendimiento en comparaci√≥n con una implementaci√≥n secuencial.

---

## üìÇ Descripci√≥n General

El script `knnParalelo.py` permite:
- Cargar datasets **Digits** o **MNIST**.
- Dividir el dataset entre procesos MPI.
- Calcular distancias Euclidianas de forma distribuida.
- Combinar resultados en el proceso maestro para predecir usando votaci√≥n mayoritaria.
- Medir precisi√≥n, tiempos de c√≥mputo y m√©tricas de rendimiento (**FLOPs**, **GFLOPS**).

---

## ‚öôÔ∏è Requisitos

Aseg√∫rate de tener instalados:

- **Python 3**  
  üëâ [Descargar](https://www.python.org/)

- **Implementaci√≥n de MPI**  
  Ejemplo: [Open MPI](https://www.open-mpi.org/) o [MPICH](https://www.mpich.org/)

- **Bibliotecas de Python**:
  - `mpi4py`
  - `numpy`
  - `scikit-learn`
  - `matplotlib` (opcional, si deseas graficar resultados)

Instala las dependencias con `pip`:

```bash
pip install mpi4py numpy scikit-learn matplotlib
```

---

## ‚ñ∂Ô∏è C√≥mo Ejecutar el Script

Ejecuta el archivo `knnParalelo.py` usando `mpiexec` o `mpirun`:

```bash
mpiexec -n <numero_de_procesos> python knnParalelo.py [dataset] [fracci√≥n]
```

**Argumentos opcionales:**
- `dataset` ‚Üí `digits` o `mnist` (por defecto: `digits`)
- `fracci√≥n` ‚Üí n√∫mero entre 0.0 y 1.0 para definir qu√© porcentaje del dataset usar. Ejemplo: `0.1` para usar 10‚ÄØ% del dataset.

---

### üìå Ejemplos

**Ejecutar usando 4 procesos con el dataset Digits (100‚ÄØ%):**
```bash
mpiexec -n 4 python knnParalelo.py
```

**Ejecutar usando 8 procesos con MNIST y solo el 10‚ÄØ% de los datos:**
```bash
mpiexec -n 8 python knnParalelo.py mnist 0.1
```

---

## üî¨ Detalles T√©cnicos

- Cada proceso recibe una **partici√≥n** de los datos de entrenamiento.
- Cada punto de prueba se eval√∫a calculando la **distancia Euclidiana** a todos los puntos de entrenamiento de su partici√≥n.
- Los `k` vecinos m√°s cercanos se env√≠an al **proceso maestro**, que combina resultados, selecciona los `k` vecinos m√°s cercanos globales y decide la clase final por **votaci√≥n mayoritaria**.
- El script mide:
  - Exactitud (**accuracy**)
  - Tiempo total, de c√≥mputo y de comunicaci√≥n.
  - **FLOPs** y **GFLOPS/segundo** estimados.

---

## üìë Archivos Clave

- `knnParalelo.py` ‚Äî Script principal para correr el algoritmo paralelo.

---

## üìñ Referencias

- [`mpi4py`](https://mpi4py.readthedocs.io/en/stable/)
- [Scikit-learn](https://scikit-learn.org/stable/)

---

## üè∑Ô∏è Licencia

Este proyecto es de uso acad√©mico. Modif√≠calo y experim√©ntalo libremente para entender y mejorar algoritmos paralelos.
